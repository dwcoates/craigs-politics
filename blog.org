let's do it
* TODO Broken stuff [0/1]
** TODO Corpus is broken. Including non-pop words

** TODO Make thesis more clear

* Introduction
For my web scraping project, I've chosen to extract politics data from craigslist.org. My original ambition, though it proved difficult to affirm, was to prove a negative correlation to pro-trump chatter with conservatism. That is, I suspected that, somewhat counter-intuitively, the politics sections of more conservative states would be the less likely source of pro-trump posts. More generally, I sought to analyze the trends of politcs discussion of craiglist.

** notes
- synopsis
* Methodology
To extract data from craigslist, I used the Python Scrapy package. I executed some 500 requests, spread over 5 hours, to obtain roughly 40,000 posts titles/times. For each of these titles, there is a corresponding state and region, with some regions are additionally divided into subregions (the New York City region, for example, consists of Brooklyn, Queens, Manhattan, etc). Each post, its time and its geographical origin are represented with a single row in a 40k row Pandas DataFrame. Data corruption was not an issue. Additionally, I employed the 2010 U.S. census, which is available from http://www.census.gov, as well as 2016 election results data, which was also extracted from http://uselectionatlas.org/ using a simple BeautifulSoup extraction script. 
* TODO Data [0/2]
** TODO number of posts
** TODO data corruption

* State Usage
** DONE Introduction
*** intro
Although the post data has attached a fairly fine-grain geographical description, I found the CL regions in general to not line up well with any census bureau categories, and even in the event of such naming correspondence, the division of regions was at least questionable. One of the datasets most prominent outliers, District of Columbia, for example, has a census population of about 600k, yet a practical metropolitan area population in the several millions, grossly skewing its contributions to state-wide statistics. Therefore, regions and subregions were largely found to be unmanageably tedious to consider seriously in any analysis. States, however, having relatively little variation between practical occupancy and census population, and have indisputable borders, are ideal for inspection. 
*** terms
**** patronage
Patronage is the raw number of posts on the politics board. 
**** usage
Usage is my measure for a states proportional interest in the politics board. It is simply the normalized ratio of patronage and state population. 
**** trumpism
Trumpism is the name for a states republican vote percentage in the general election. It is used as a rough measure of how pro-Trump that state is.
** Population
*** Sample
We can get a feel for the distribution by taking a look at the following sample from the state_usage table
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes  :exports both
print(pd.concat([state_usage[:5], state_usage_space, state_usage[-5:].sort_values("usage")]))
#+END_SRC
#+RESULTS:
:RESULTS:
             patronage population       usage
Colorado          1982    5029196           1
Hawaii             445    1360301     0.81696
Montana            286     989415     0.71289
Oregon            1094    3831074    0.703323
Nevada             770    2700551    0.702141
*SPACE*         ------     ------      ------
North Dakota        19     672591           0
Vermont             18     625741  0.00141296
Kansas             106    2853118   0.0243361
Wyoming             22     563626   0.0294766
New Jersey         400    8791894   0.0471436
:END:
    
Seemingly some correlation between low population and low usage is evident from this table. However, the states for which the politics board is most popular are also generally small. This correlation is explored more by some political investigation, however, first outliers musbt be removed from the data.

*** Outliers
There are two major outlying states in the dataset: Colorodo and District of Columbia. 
**** Colorodo
We can see from the following that Colorado is an extreme outlier, being the fifth most popular state, yet the 23rd most populous. 
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py6320WCb.png :exports both
top_five = state_usage.sort_values("patronage")[-5:][::-1]
fig = plt.figure() # Create matplotlib figure

ax = fig.add_subplot(111) # Create matplotlib axes
ax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.

width = 0.2

top_five.patronage.plot(kind='bar', color='#992255', ax=ax, width=width, position=1)
top_five.population.plot(kind='bar', color='#CC7733', ax=ax2, width=width, position=0)

ax.set_ylabel('Patronage')
ax2.set_ylabel('Population')

plt.show()
#+END_SRC
#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/py6320WCb.png]]
Denver, for example, is especially large. Despite having a metropolitan area of less than 3 million people, Denver sees a patronage of 1187.
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes  :exports both
num_denver_posts = len(usa[usa.region == "denver, CO"])
#+END_SRC

#+RESULTS:
:RESULTS:
:END:

By comparison, the "new york city" region, which is expansive enough as to include subregions like "new jersey", "long island", "fairfield", etc, has fewer posts, at 1006. 
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes :exports both
nyc_subregions = usa.groupby("region").get_group("new york city").subregion.unique().tolist()

num_nyc_posts = len(usa[usa.region == "new york city"])
#+END_SRC
#+RESULTS:
:RESULTS:
:END:

**** District of Columbia
While I found Colorado to be an inexplicable anamoly, it was also justifiably accurate. District of Columbia, having a Republican voting rate of ~4% and the strict usage rate similar to that of Colorado, coupled with it's nebulous geographic distinction, meant its results were too extreme to consider in analysis.
** Correlations
*** Distributions
We can see the correlations between patronage, population, and usage, here. We of course expect correlation between patronage and population. Coolness represents lack of correlation.
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/img/py224159fd.png :exports both
corr = state_usage.corr()
fig, ax = plt.subplots(figsize=(4, 4))
ax.matshow(corr)
plt.xticks(range(len(corr.columns)), corr.columns);
plt.yticks(range(len(corr.columns)), corr.columns);
#+END_SRC

#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/img/py224159fd.png]]
We can see that usage and population correlate considerably. In more concrete numerical terms, using the pearson correlation coefficient:
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes
norm_usage = (state_usage - state_usage.min()) / (state_usage.max() - state_usage.min())
stats = pd.DataFrame({"mean": norm_usage.mean(), "median": norm_usage.median()})
print(("Mean/median of normalized state usage metrics:\n{0}").format(stats))
#+end_src
#+RESULTS:
:RESULTS:
Mean/median of normalized state usage metrics:
                mean    median
patronage   0.197488  0.091557
population  0.152608  0.105552
usage       0.264764  0.203740
:END:
We can see that usage has less variance than patronage and population, which we should expect. Perhaps it is somewhat more than expected, however. We expect (perhaps naively) for usage to coincide with population/patronage closely. 
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py6320cwT.png :exports both
norm_usage.plot(kind="density", title="Normalized PDF estimations", sharey=True)
#+END_SRC

#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/py6320cwT.png]]

*** Usage per state
The distribution of usage among states seems reasonable.
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/img/py22415jSF.png :exports both
ax = plt.subplot(111)  
ax.spines["top"].set_visible(False)  
ax.spines["right"].set_visible(False)  
    
ax.get_xaxis().tick_bottom()  
ax.get_yaxis().tick_left()  

plt.xlabel("Usage", fontsize=12)  
plt.ylabel("States", fontsize=12)     

plt.suptitle('State Usage Distribution', fontsize=14) 

plt.hist(state_usage.usage,
         color="#661111", bins=17)  
#+END_SRC

#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/img/py22415jSF.png]]

#+END_SRC
*** Politics
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/img/py22415k-v.png :exports both
post_politics = usa.join(states.trumpism, how="outer", on="state")

post_politics.filter(["trumpism", "state"]).plot(kind="hist", bins=14, color=["#FF9911"], title="Trumpism frequency distribution")
#+END_SRC

#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/img/py22415k-v.png]]

* Text Qualities
** Introduction
   Text usage is interesting to consider, but difficult to evaluate. While sampling provides surpritising intuitions about the data, demonstration of any following ideas is quite difficult. The follow demonstrates some efforts to support some of my intuitive ideas about the obtained dat
** General
*** Vocabulary [0/1]
Investigating the discrepency between democrat/republican word usage, we find some discrepencies in the most used common words:
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes :exports both
lib_con_ratio = pd.DataFrame(posts_corpus).join(ratio.sort_values(ascending=False), how="inner")

print(lib_con_ratio[:5])
#+END_SRC
#+RESULTS:
:RESULTS:
       counts  dem/rep ratio
of        665       5.803922
news      841       5.394366
is        668       5.215686
us        544       4.678571
obama    1757       4.254545
:END:
We find that "against", "how", and "won" have extreme preference for "liberal" states. The reasons are in fact not obvious. Some random sampling of such posts reveals possibly surprisingly pro-Trump sentiment: 
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes  :exports both
  print(pd.concat([find_strs("against"),
                   find_strs("how"),
                   find_strs("won")]).sample(10))
#+END_SRC
#+RESULTS:
:RESULTS:
17955                                How to vote No to Nuclear Weapons
21075            Trump is a sniveling pussy. Why won't the idiot admit
25295                     re:Wrong Again - Trump WON the popular vote!
20896                                      How To Spot A Stupid Person
17811                             RE:  4 Dumb ass who against TRUMP ..
2822                                     part of our wonderful society
16175    This is "how" peaceful Allah muslims thank us "providers"....
36715                                Lightworkers united against Greed
23798            re,  Pigfest, How Government Hogs & Wastes Your Money
18887                                          How can you comprehend?
dtype: object
:END:
Looking at the general word sentiment:
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py31406ImT.png :exports both
p = posts_corpus[:50].sort_values(ascending=True)
ax.spines["top"].set_visible(False)  
ax.spines["right"].set_visible(False)  
    
ax.get_xaxis().tick_bottom()  
ax.get_yaxis().tick_left()  

p.plot(kind="bar", title="Distinct word distribution")
#+END_SRC

#+RESULTS:
[[file:/home/dodge/workspace/craig-politics/py31406ImT.png]]

**** TODO Fix distinct word distribution including non-pop words, for some reason 
*** word cloud [0/1]
**** TODO Show cloud png here
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py31406VwZ.png :exports both

#+END_SRC
*** TODO Semantics 
*** TODO Unicode
** Politics [0/1]
*** What words are used most by Democrats?
#+BEGIN_SRC ipython :session :file  :exports both :results output raw drawer :noweb yes
  lib_words = words(df=post_politics[post_politics.trumpism < .45],
                    no_pop=True).rename("libs")
  conserv_words = words(df=post_politics[post_politics.trumpism > .55],
                        no_pop=True).rename("conservs")
   
  rat = lambda df: df.libs/df.conservs
  ratio = pd.DataFrame().join([lib_words[lib_words >= 50],
                               conserv_words[conserv_words >= 50]],
                              how="outer").apply(rat, axis=1).dropna()
  ratio = ratio.rename("dem/rep ratio")
  lib_con_ratio = pd.DataFrame(posts_corpus).join(ratio.sort_values(ascending=False),
                                                  how="inner")
  lib_con_ratio.sort("dem/rep ratio", ascending=False, inplace=True)
  print(lib_con_ratio[:10])
#+END_SRC
#+RESULTS:
:RESULTS:
         counts  dem/rep ratio
of          665       5.803922
news        841       5.394366
is          668       5.215686
us          544       4.678571
obama      1757       4.254545
in          548       4.113208
again       614       4.000000
clinton     667       3.985075
to         1017       3.840000
not         993       3.371681
:END:
*** TODO Diversity of words vs trumpism
#+BEGIN_SRC ipython :session :file  :exports both

#+END_SRC
*** "liberals" vs "conservatives"
**** Pluralization
The singular version of "conservative" is used a bit more than half as much as the pluralization. By contrast, the singular version of "liberal" is used more than twice as much as the pluralization. I suspect this is because "liberal" is a perjorative in common nomenclature, while "conservative" doesn't really hold the same weight as an insult.
#+BEGIN_SRC ipython :session :file  :exports both :results output raw drawer :noweb yes
print(" singular/plural:\n" +
      "'conservative': {0:.3f}\n" +
      "'liberal': " +
      "{1:.3f}\n").format(posts_corpus["conservative"]/float(posts_corpus["conservatives"]),
                          posts_corpus["liberal"]/float(posts_corpus["liberals"]))

#+END_SRC
#+RESULTS:
:RESULTS:
 singular/plural:
'conservative': 0.628
'liberal': 2.198

:END:

**** Usage
"liberal" is used far more often than "conservative". The pluralizations, respectively, are comparitively not quite as distinguished. This is expected, for previously mentioned reasons; pluralizations may still be used as a means to negatively generalize.
#+BEGIN_SRC ipython :session :file  :exports both :results output raw drawer :noweb yes
  liberal = float(posts_corpus["liberal"])
  liberal_p = float(posts_corpus["liberals"])
  conserv = float(posts_corpus["conservative"])
  conserv_p = float(posts_corpus["conservatives"])


  print ("liberal/conservative: {0:.2f}\n" +
   "liberals/conservatives: {1:.2f}\n" +
   "liberal(s)/conservative(s): {2:.2f}" +
    "") .format(liberal/conserv,
                  liberal_p/conserv_p,
                  (liberal+liberal_p)/(conserv+conserv_p))

#+END_SRC

#+RESULTS:
:RESULTS:
liberal/conservative: 18.07
liberals/conservatives: 5.16
liberal(s)/conservative(s): 10.14
:END:
**** Capitalization
We see that "liberal" is capitalized at a rate 13x greater than the rate of capitalization of "conservative". 
#+BEGIN_SRC ipython :session :results output raw drawer :noweb yes :exports both
lib_cap = eval_strs("trump").sum(numeric_only=True)
conserv_cap = eval_strs("liberal").sum(numeric_only=True)

lib_con_cap_rat = lib_cap/conserv_cap

print(lib_con_cap_rat)
#+END_SRC

#+RESULTS:
:RESULTS:
proper       10.595062
uppercase    13.428571
lower         1.077206
dtype: float64
:END:
*** "trump" vs "clinton" vs "obama"
**** "trump" usage / total usage
#+BEGIN_SRC ipython :session :file  :exports both

#+END_SRC
**** "trump" usage / trumpism
**** upcase usage / trumpism
**** trumpism
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py6320hB1.png :exports both
trump_posts = usa.join(voting, on="state").join(find_strs("trump"), how="inner")

print "Sampling posts from especially anti-trump states:\n{0}".format(t[t.trumpism < .4].title.sample(10))

print "\nPolitically liberal states composing the above sampling:\n{0}".format(t[t.trumpism < .4].groupby("state").sum().index.tolist())
#+END_SRC
*** Semantics
#+BEGIN_SRC ipython :session :file /home/dodge/workspace/craig-politics/py6320TLE.png :exports both
  from textblob import TextBlob

  def semants(text):
      blob = TextBlob(text)
      ss = 0
      for sentence in blob.sentences:
          ss += sentence.sentiment.polarity

      return float(ss)/len(blob.sentences)

 semantics = ascii_posts.title.map(lambda x: semants(x)).rename("semants")
 semant = eval_strs("trump", df=ascii_posts).join(pd.DataFrame(semantics))
 sems_usa = semant.join(usa, how="inner")
 trumps_semantics = sems_usa.groupby("state").mean().join(voting, how="inner").sort_values("semants").corr()

trumps_semantics
#+END_SRC

*** Unicode
The number of posts containing non-ascii characters was surprisingly small:
#+BEGIN_SRC ipython :session   :exports both :results output raw drawer :noweb yes
print ("{0:,} of {1:,} total posts were non-ascii ({2:.2f}%), confined to {3} "
       + "states.").format(len(nonascii_posts),
                       len(usa),
                       len(nonascii_posts)/float(len(usa)) * 100,
                       len(distinct_states))
#+END_SRC
However, influence for these posts can be seen by looking at the main outlier, Pennsylvania:
#+BEGIN_SRC ipython :session  :exports both :tangle ./politics.py :results output raw drawer :noweb yes 
pennsylvania = nonascii_posts[nonascii_posts["state"] == "Pennsylvania"]

print("\nA single Trump memester seems to be responsible for the chaos " +
      "in Pennsylvania.\n" + "I suspect that these crazy unicode posts " +
      "are mostly done by a very small\nset of people, though there is " +
      "no way to tell.")
print "\nRandom sample of 5 non-ascii Pennsylvania posts"
print pennsylvania["title"][:5]

pennsylvania.groupby("region").count()

post_uniqueness = pennsylvania.title.nunique()/float(len(pennsylvania.title))

post_uniqueness
#+END_SRC

#+RESULTS:
:RESULTS:

A single Trump memester seems to be responsible for the chaos in Pennsylvania.
I suspect that these crazy unicode posts are mostly done by a very small
set of people, though there is no way to tell.

Random sample of 5 non-ascii Pennsylvania posts
18398           ðŸ™ŠðŸ™‰The ZOMBIES Are ComingðŸ™‰ðŸ™Š
18410    ðŸ’¥DONALD J. TRUMPðŸ’¥[Need a Tissue Anyone]
18418           ðŸ�µðŸ™‰The Zombies Are ComingðŸ�µðŸ™‰
18426       ðŸ‘‘HAPPY NEW YEARSðŸ‘‘DONALD J. TRUMPðŸ‘‘
18430           ðŸ™ŠðŸ™‰The ZOMBIES Are ComingðŸ™‰ðŸ™Š
Name: title, dtype: object
:END:

* Conclusion
The distribution posts and the favor of those posts across the politics sections is somewhat surprising. I suspect that this is evidence of cultural normalization in the face of resistance+anonimity: faceless, nameless interaction coupled with outspokenness against relatively strict local social norms. This has proven more difficult to prove than I initially suspected. While any amount of ransom sampling of the posts allows me to be confident in this theory, convincing proof would most likely involve a tedious, exhausive effort.
