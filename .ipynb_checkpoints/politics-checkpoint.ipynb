{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mtl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pandas\n",
    "\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "38,981 total posts exctracted. The most popular state was California,\n",
      "and the most popular region was, surprisingly, denver, CO.\n"
     ]
    }
   ],
   "source": [
    "# read us data collected by craigcrawler\n",
    "usa_raw = pd.read_csv(\"data/us.csv\", index_col=0)\n",
    "post_count_total_raw = len(usa_raw)\n",
    "post_count_by_state_raw = usa_raw.groupby(\"state\").count()[\"title\"].sort_values(ascending=False)\n",
    "post_count_by_region_raw = usa_raw.groupby(\"region\").count()[\"title\"].sort_values(ascending=False)\n",
    "\n",
    "print (\"\\n{0:,} total posts exctracted. The most popular state was {1},\\n\" +\n",
    "       \"and the most popular region was, surprisingly, {2}.\").format(post_count_total_raw,\n",
    "                                                                     post_count_by_state_raw.index[0],\n",
    "                                                                     post_count_by_region_raw.index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some preprocessing to check data corrupted files\n",
    "assert len(usa_raw[\"state\"].unique()) == 52\n",
    "len(usa_raw[\"region\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# How responsible is trump for my corrupted data?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mississippi', '0400000US28'),\n",
       " ('Oklahoma', '0400000US40'),\n",
       " ('Delaware', '0400000US10'),\n",
       " ('Minnesota', '0400000US27'),\n",
       " ('Illinois', '0400000US17')]"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of census keys, if curious:\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# US census data for 2010 from the census bureau\n",
    "#\n",
    "\n",
    "# Census data is not labelled exactly as my data is. Some states are named a little differently,\n",
    "# and regions are almost never named similarly. These have to be resolved.\n",
    "\n",
    "census = pd.read_csv(\"data/census/DEC_10_DP_DPDP1_with_ann.csv\")[1:]\n",
    "# keys for the census data. Only really care about two of them (there are hundreds):\n",
    "TOT_NUM_ID = \"HD01_S001\" # total number key\n",
    "TOT_PER_ID = \"HD02_S001\" # total percent key\n",
    "\n",
    "# Keys for geography stuff. Table is an index table.\n",
    "# These keys are used as index for census table.\n",
    "census_keys = pd.read_csv(\"data/census/DEC_10_DP_G001_with_ann.csv\")[1:]\n",
    "GEO_KEY = \"GEO.display-label\"\n",
    "GEO_ID = \"GEO.id\"\n",
    "# keys used to reference states in census\n",
    "census_states_keys = dict(zip(list(census_keys[GEO_KEY]), list(census_keys[GEO_ID][:52])))\n",
    "\n",
    "print \"Sample of census keys, if curious:\"\n",
    "zip(list(census_states_keys), list(census_states_keys.values()))[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Puerto Rico'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-641-a6309db01c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmisnamed_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcensus_states_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpost_count_by_state_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmisnamed_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dodge/.local/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dodge/.local/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1992\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1993\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1994\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1995\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Puerto Rico'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Standardizing census and cl data names This may have to be limited\n",
    "# to states names. Regions will be, at the very least, a huge pain.\n",
    "# Most likely will be unresolvable.\n",
    "#\n",
    "misnamed_states = []\n",
    "for name in census_states_keys:\n",
    "    if post_count_by_state_raw[name] < 0: misnamed_states.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "199 of 38,981 total posts were non-ascii (0.51%), confined to 23 states.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ascii vs. unicode\n",
    "#\n",
    "\n",
    "def check_ascii(post):\n",
    "    \"\"\"\n",
    "    Determines whether a title is properly encoded.\n",
    "    \"\"\"\n",
    "    title = post[\"title\"]\n",
    "    try:\n",
    "        title.encode('ascii')\n",
    "        return True\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "\n",
    "ascii_titles_tv = usa_raw.apply(check_ascii, axis=1)\n",
    "nonascii_posts = usa_raw[~ascii_titles_tv]\n",
    "\n",
    "distinct_states = nonascii_posts[\"state\"].unique()\n",
    "print (\"\\n{0:,} of {1:,} total posts were non-ascii ({2:.2f}%), confined to {3} \"\n",
    "       + \"states.\").format(len(nonascii_posts),\n",
    "                       total_posts_raw,\n",
    "                       len(nonascii_posts)/float(total_posts_raw) * 100,\n",
    "                       len(distinct_states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top ten most popular unicode states:\n",
      "state\n",
      "Pennsylvania    18\n",
      "Maryland         8\n",
      "New York         7\n",
      "California       6\n",
      "Arizona          5\n",
      "Florida          5\n",
      "Washington       4\n",
      "Texas            4\n",
      "Colorado         3\n",
      "Connecticut      3\n",
      "Name: title, dtype: int64\n",
      "ðŸ™ŠðŸ™‰The ZOMBIES are comingðŸ™ŠðŸ™‰\n",
      "\n",
      "A single Trump memester seems to be responsible for the chaos in Pennsylvania.\n",
      "I suspect that these crazy unicode posts are mostly done by a very small\n",
      "set of people, though there is no way to tell.\n",
      "\n",
      "Random sample of 5 non-ascii Pennsylvania posts\n",
      "18505                     ðŸ™ŠðŸ™‰The ZOMBIES are comingðŸ™ŠðŸ™‰\n",
      "18514    ðŸ‘‘HAPPY NEW YEARSðŸ‘‘ America ðŸ‘‘ DONALD J.TRUMPðŸ‘‘\n",
      "18515    ðŸŽ€HAPPY NEW YEARðŸŽ€ AMERICA ðŸ‘‘ DONALD J. TRUMPðŸ‘‘\n",
      "18530              ðŸ’¥DONALD J. TRUMPðŸ’¥[Need a Tissue Anyone]\n",
      "18540                                     ðŸ—½Keep on CryingðŸ—½\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ascii vs. unicode\n",
    "#\n",
    "\n",
    "nonascii_states_count = nonascii_posts.groupby(\n",
    "    \"state\").title.nunique().sort_values(ascending=False)\n",
    "print \"\\nTop ten most popular unicode states:\"\n",
    "print nonascii_states_count[:10]\n",
    "\n",
    "pennsylvania = nonascii_posts[nonascii_posts[\"state\"] == \"Pennsylvania\"]\n",
    "print pennsylvania[\"title\"].tolist()[0]\n",
    "\n",
    "print(\"\\nA single Trump memester seems to be responsible for the chaos \" +\n",
    "      \"in Pennsylvania.\\n\" + \"I suspect that these crazy unicode posts \" +\n",
    "      \"are mostly done by a very small\\nset of people, though there is \" +\n",
    "      \"no way to tell.\")\n",
    "print \"\\nRandom sample of 5 non-ascii Pennsylvania posts\"\n",
    "print pennsylvania[\"title\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top ten most popular states\n",
      "state\n",
      "California      3801\n",
      "Florida         3585\n",
      "Texas           3155\n",
      "New York        2358\n",
      "Colorado        2066\n",
      "Pennsylvania    1881\n",
      "Washington      1400\n",
      "Ohio            1396\n",
      "Arizona         1381\n",
      "Michigan        1359\n",
      "Name: title, dtype: int64\n",
      "\n",
      "Top ten most popular regions\n",
      "region\n",
      "denver, CO               1271\n",
      "new york city            1023\n",
      "seattle-tacoma            883\n",
      "pittsburgh, PA            801\n",
      "phoenix, AZ               790\n",
      "south florida             750\n",
      "los angeles               728\n",
      "minneapolis / st paul     700\n",
      "dallas / fort worth       681\n",
      "SF bay area               679\n",
      "Name: title, dtype: int64\n",
      "\n",
      "\n",
      "7 regions in Colorado\n"
     ]
    }
   ],
   "source": [
    "state_patronage = usa.groupby('state').count()[\"title\"].sort_values(ascending=False)\n",
    "region_patronage = usa.groupby('region').count()[\"title\"].sort_values(ascending=False)\n",
    "\n",
    "print \"\\nTop ten most popular states\"\n",
    "print state_patronage[:10]\n",
    "\n",
    "# Denver is about 10 times as populous as nyc, for example\n",
    "print \"\\nTop ten most popular regions\"\n",
    "print region_patronage[:10]\n",
    "\n",
    "print \"\\n\\n{0} regions in Colorado\".format(usa[usa['state'] == \"Colorado\"][\"region\"].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "politics.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
